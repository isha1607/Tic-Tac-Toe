# -*- coding: utf-8 -*-
"""CC3602.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MHLOS5k4t2GaE9A2g83CE8dkpXy5Vlg_
"""

import numpy as np
import cv2
import os
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Directory where your dataset is stored
dataset_path = 'path_to_dataset'

# Load dataset
def load_data(dataset_path):
    images = []
    labels = []
    class_names = os.listdir(dataset_path)
    for class_name in class_names:
        class_path = os.path.join(dataset_path, class_name)
        for image_name in os.listdir(class_path):
            image_path = os.path.join(class_path, image_name)
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            image = cv2.resize(image, (64, 64))  # Resize images to 64x64
            images.append(image)
            labels.append(class_name)
    images = np.array(images)
    labels = np.array(labels)
    return images, labels

images, labels = load_data(dataset_path)

# Encode labels
label_dict = {label: idx for idx, label in enumerate(np.unique(labels))}
labels = np.array([label_dict[label] for label in labels])

# Normalize images
images = images / 255.0

# Split data
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
X_train = X_train.reshape(-1, 64, 64, 1)
X_test = X_test.reshape(-1, 64, 64, 1)

# Convert labels to categorical
y_train = to_categorical(y_train, num_classes=len(label_dict))
y_test = to_categorical(y_test, num_classes=len(label_dict))

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Build the model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(label_dict), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Function to preprocess frame for prediction
def preprocess_frame(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, (64, 64))
    normalized = resized / 255.0
    reshaped = np.reshape(normalized, (1, 64, 64, 1))
    return reshaped

# Function to predict gesture
def predict_gesture(model, frame):
    preprocessed = preprocess_frame(frame)
    prediction = model.predict(preprocessed)
    return np.argmax(prediction), np.max(prediction)

# Load the trained model
model_path = 'path_to_trained_model.h5'
model.load_weights(model_path)

# Start video stream
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gesture_idx, confidence = predict_gesture(model, frame)
    gesture = list(label_dict.keys())[list(label_dict.values()).index(gesture_idx)]

    cv2.putText(frame, f'Gesture: {gesture} ({confidence*100:.2f}%)', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
    cv2.imshow('Gesture Recognition', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

